{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ae82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3 as db\n",
    "from sqlite3 import Error\n",
    "\n",
    "%run C:\\Users\\Joshua\\Jupyter_Notebook_Folders\\APIkeys.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb32b58",
   "metadata": {},
   "source": [
    "### Functions for working with SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "221ed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_name):\n",
    "    \"\"\" \n",
    "    create an SQLite database\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = db.connect(db_name)\n",
    "        #print(db.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "            \n",
    "def create_connection(db_name):\n",
    "    \"\"\" \n",
    "    create a database connection to the SQLite database\n",
    "        specified by db_name\n",
    "    return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = db.connect(db_name)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def check_table_exists(tbl_name, db_name): \n",
    "    \"\"\"\n",
    "    Check if table exists\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    exists = 0\n",
    "    c.execute(\"SELECT count(name) FROM sqlite_master WHERE type='table'\")\n",
    "    if c.fetchone()[0] == 0:\n",
    "        print(\"No tables in DB.\")\n",
    "    else:\n",
    "        try:\n",
    "            c.execute(\"SELECT COUNT(name) FROM sqlite_master WHERE type = 'table' AND name='\" + seriesID+\"';\")\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "        if c.fetchone()[0] == 1:\n",
    "            exists = 1\n",
    "            \n",
    "        else:\n",
    "            print(\"Table does not exist\")        \n",
    "    conn.close()\n",
    "    \n",
    "    return exists \n",
    "    \n",
    "    \n",
    "def create_table(input_df, tbl_name, db_name):\n",
    "    \"\"\"\n",
    "    create table\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    if not check_table_exists(tbl_name ,db_name):\n",
    "        try: \n",
    "            input_df.to_sql(tbl_name, conn)\n",
    "            print(\"Created \", tbl_name, \" table.\")\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"Table was not added to the DB\")       \n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "def check_duplicate_data(df, tbl_name, db_name):\n",
    "    \"\"\"\n",
    "    check if the data to be entered already exists in the table\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    df_not_dup_data = pd.DataFrame(columns = list(df.columns))\n",
    "    df_dup_data = pd.DataFrame(columns = list(df.columns))\n",
    "    df_inconsistent_data = pd.DataFrame(columns = list(df.columns))\n",
    "    \n",
    "    # Check if data already exists in DB\n",
    "    for i, row in df.iterrows():\n",
    "        c.execute(\"SELECT date, value FROM \" + tbl_name + \" WHERE date = ?;\", (df.loc[i][\"date\"],))\n",
    "        queryOut = c.fetchall()\n",
    "        if len(queryOut) == 0:\n",
    "            df_not_dup_data = pd.concat([df_not_dup_data, df.loc[[i]]])\n",
    "        elif queryOut[0][1] == df.loc[i][\"value\"]:\n",
    "            df_dup_data = pd.concat([df_dup_data, df.loc[[i]]])\n",
    "            #print(seriesID, \" data for \", df.iloc[i][\"date\"], \" already exists with same value as API:\", queryOut[0][1])\n",
    "        elif queryOut[0][1] != df.loc[i][\"value\"]:\n",
    "            df_inconsistent_data = pd.concat([df_inconsistent_data, df.loc[[i]]])\n",
    "            #print(seriesID, \" \", df.ioc[i][\"date\"], \"DB DATA: \", queryOut[0][1], \" DOES NOT MATCH INPUT DATA: \", )\n",
    "    conn.close()\n",
    "    \n",
    "    df_not_dup_data = df_not_dup_data.sort_values(by=['date'])\n",
    "    \n",
    "    return df_not_dup_data, df_dup_data, df_inconsistent_data\n",
    "\n",
    "\n",
    "def add_to_database(df_EntryData, tbl_name, db_name):  \n",
    "    \"\"\"\n",
    "    Add dataframe to \n",
    "    database: db_name \n",
    "    table: tbl_name\n",
    "    \"\"\"\n",
    "    conn = create_connection(db_name)    \n",
    "    try:\n",
    "        df_EntryData.to_sql(seriesID, con=conn, if_exists='append')\n",
    "        print(\"Data added to DB: \\n\", df_EntryData)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        print(\"Data was not added to the DB\")\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "def get_max_index(tbl_name, db_name):\n",
    "    '''\n",
    "    Get the maximum index value of the specified tbl_name\n",
    "    '''\n",
    "    conn = create_connection(db_name)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute(\"SELECT MAX([index]) FROM \" + seriesID)\n",
    "        max_index = c.fetchone()[0]\n",
    "        return max_index\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "\n",
    "def table_to_df(tbl_name, db_name):\n",
    "    conn = db.connect(db_name)\n",
    "    try:\n",
    "        df_fromDB = pd.read_sql_query(\"SELECT * FROM \" + tbl_name + \";\", conn)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    conn.close()\n",
    "    \n",
    "    return df_fromDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cd000",
   "metadata": {},
   "source": [
    "### Get data from BLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe4a0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BLS_data(seriesID, startyear, endyear):\n",
    "    base_url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'  #this will not change\n",
    "    headers = {'Content-type': 'application/json'}  #This will not changed !\n",
    "\n",
    "    # For the key seriesid enter a list of series names you wish to download\n",
    "    # For the key startyear enter the start year inside \"\"\n",
    "    # For the key endyear enter the end year inside \"\"\n",
    "    \n",
    "    parameters = {\n",
    "        \"seriesid\":[seriesID], \n",
    "        \"startyear\":str(startyear), \n",
    "        \"endyear\":str(endyear),\n",
    "        \"catalog\":True, \n",
    "        \"calculations\":False, \n",
    "        \"annualaverage\":False,\n",
    "        \"aspects\":False,\n",
    "        \"registrationkey\":os.environ['BLS_API_key'] \n",
    "     }\n",
    "\n",
    "    data = json.dumps(parameters) # Converts the Python dictionary to JSON\n",
    "\n",
    "    p = requests.post(base_url, data=data, headers=headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    \n",
    "    message = \"\"\n",
    "    if json_data['message']:\n",
    "        message = \"For series \" + seriesID + \", no data for years: \"\n",
    "        for i in range(len(json_data['message'])):\n",
    "            message += json_data['message'][i][-4:] + \", \"\n",
    "    \n",
    "    return message, json_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c00f9",
   "metadata": {},
   "source": [
    "### Create and Format Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9946cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_json_for_sqlite(json_data, seriesID, db_name):\n",
    "    # If table exists get the max \n",
    "    index_start = 0\n",
    "    if check_table_exists(seriesID, \"MacroData.sqlite3\") != 0:\n",
    "        index_start = get_max_index(seriesID, \"MacroData.sqlite3\") + 1\n",
    "\n",
    "    # Create dataframe from JSON\n",
    "    df = pd.DataFrame(json_data['Results']['series'][0]['data'])\n",
    "\n",
    "    # Format date column and sort by date\n",
    "    df['date'] = df['year'] + df['period']\n",
    "    df['date'] = df['date'].str.replace('M', '-')\n",
    "    df['date'] = df['date'].astype('string')\n",
    "    df = df.sort_values(by=['date'], ignore_index=True)\n",
    "\n",
    "    # Set the index using the value from the max index in the db table\n",
    "    df[\"index\"] = range(index_start, index_start + len(df.index))\n",
    "    df = df.set_index(df[\"index\"])\n",
    "\n",
    "    df = df.drop(columns=['footnotes', 'index'])\n",
    "    df['value'] = df['value'].astype(float)\n",
    "    df['description'] = json_data['Results']['series'][0]['catalog']['survey_name'] + ', ' + json_data['Results']['series'][0]['catalog']['series_title']\n",
    "    \n",
    "    df, df_dup_data, df_inconsistent_data = check_duplicate_data(df, seriesID, db_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf1453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
